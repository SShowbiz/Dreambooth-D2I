{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 6000, 22698 MiB, 12137 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 12820 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 19222 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 19238 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 19244 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 8250 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 21860 MiB\n",
      "Quadro RTX 6000, 22698 MiB, 22128 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter_compare_view\n",
      "  Downloading jupyter_compare_view-0.2.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter_compare_view) (9.3.0)\n",
      "Requirement already satisfied: ipykernel>=5.0.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter_compare_view) (6.20.2)\n",
      "Requirement already satisfied: ipython>=6.0.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter_compare_view) (8.9.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (6.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (8.0.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (1.6.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (5.9.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (25.0.0)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (5.9.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (23.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (1.5.6)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipykernel>=5.0.0->jupyter_compare_view) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (3.0.36)\n",
      "Requirement already satisfied: stack-data in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (0.6.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (2.14.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/envs/ldm/lib/python3.8/site-packages (from ipython>=6.0.0->jupyter_compare_view) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.0.0->jupyter_compare_view) (0.8.3)\n",
      "Collecting Jinja2>=2.11.3\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=5.0.0->jupyter_compare_view) (5.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=5.0.0->jupyter_compare_view) (2.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=5.0.0->jupyter_compare_view) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=5.0.0->jupyter_compare_view) (3.12.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel>=5.0.0->jupyter_compare_view) (2.6.2)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.0.0->jupyter_compare_view) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/ldm/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=6.0.0->jupyter_compare_view) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=5.0.0->jupyter_compare_view) (1.16.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/envs/ldm/lib/python3.8/site-packages (from stack-data->ipython>=6.0.0->jupyter_compare_view) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from stack-data->ipython>=6.0.0->jupyter_compare_view) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/ldm/lib/python3.8/site-packages (from stack-data->ipython>=6.0.0->jupyter_compare_view) (2.2.1)\n",
      "Installing collected packages: MarkupSafe, Jinja2, jupyter-compare-view\n",
      "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.2 jupyter-compare-view-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jupyter_compare_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=stabilityai/stable-diffusion-2-depth\n",
      "env: INSTANCE_DIR=/workspace/Lab/DCT-Net/DCTNet/datasets/limjukyung_aligned_512\n",
      "env: CLASS_DIR=/workspace/Lab/DCT-Net/DCTNet/datasets/ffhq_512_100\n",
      "env: OUTPUT_DIR=/workspace/Lab/dreambooth_depth2img/output\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Fill in these environment variables\n",
    "%env MODEL_NAME=stabilityai/stable-diffusion-2-depth\n",
    "%env INSTANCE_DIR=/workspace/Lab/DCT-Net/DCTNet/datasets/limjukyung_aligned_512\n",
    "%env CLASS_DIR=/workspace/Lab/DCT-Net/DCTNet/datasets/ffhq_512_100\n",
    "%env OUTPUT_DIR=/workspace/Lab/dreambooth_depth2img/output\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/opt/conda/envs/ldm/lib/python3.8/site-packages/accelerate/accelerator.py:231: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ðŸ¤— Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/ldm/lib/python3.8/site-packages/accelerate/accelerator.py:336: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "==============================WARNING: DEPRECATED!==============================\n",
      "WARNING! This version of bitsandbytes is deprecated. Please switch to `pip install bitsandbytes` and the new repo: https://github.com/TimDettmers/bitsandbytes\n",
      "==============================WARNING: DEPRECATED!==============================\n",
      "Steps:   0%|               | 1/300 [00:05<26:04,  5.23s/it, loss=0.225, lr=1e-6]Traceback (most recent call last):\n",
      "  File \"train_dreambooth.py\", line 838, in <module>\n",
      "    main(args)\n",
      "  File \"train_dreambooth.py\", line 762, in main\n",
      "    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/accelerate/utils/operations.py\", line 489, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/torch/amp/autocast_mode.py\", line 12, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/unet_2d_condition.py\", line 515, in forward\n",
      "    sample = upsample_block(\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/unet_2d_blocks.py\", line 1582, in forward\n",
      "    hidden_states = attn(\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/transformer_2d.py\", line 265, in forward\n",
      "    hidden_states = block(\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/attention.py\", line 291, in forward\n",
      "    attn_output = self.attn1(\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/cross_attention.py\", line 160, in forward\n",
      "    return self.processor(\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/cross_attention.py\", line 239, in __call__\n",
      "    attention_probs = attn.get_attention_scores(query, key, attention_mask)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/diffusers/models/cross_attention.py\", line 188, in get_attention_scores\n",
      "    attention_scores = torch.baddbmm(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 320.00 MiB (GPU 0; 22.17 GiB total capacity; 20.91 GiB already allocated; 120.81 MiB free; 21.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Steps:   0%|               | 1/300 [00:06<32:49,  6.59s/it, loss=0.225, lr=1e-6]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/ldm/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 1097, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/opt/conda/envs/ldm/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 552, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/envs/ldm/bin/python', 'train_dreambooth.py', '--mixed_precision=fp16', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-depth', '--pretrained_txt2img_model_name_or_path=stabilityai/stable-diffusion-2-1-base', '--train_text_encoder', '--instance_data_dir=/workspace/Lab/DCT-Net/DCTNet/datasets/limjukyung_aligned_512', '--class_data_dir=/workspace/Lab/DCT-Net/DCTNet/datasets/ffhq_512_100', '--output_dir=/workspace/Lab/dreambooth_depth2img/output', '--with_prior_preservation', '--prior_loss_weight=1.0', '--instance_prompt=a photo of limjukyung person face', '--class_prompt=a photo of person face', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=1e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--num_class_images=200', '--max_train_steps=300', '--use_8bit_adam']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "# !python -m debugpy --listen 0.0.0.0:5678 --wait-for-client \\\n",
    "!CUDA_VISIBLE_DEVICES=6,7 accelerate launch \\\n",
    "  train_dreambooth.py \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "  --pretrained_txt2img_model_name_or_path=\"stabilityai/stable-diffusion-2-1-base\" \\\n",
    "  --train_text_encoder \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --instance_prompt=\"a photo of limjukyung person face\" \\\n",
    "  --class_prompt=\"a photo of person face\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_class_images=200 \\\n",
    "  --max_train_steps=300 \\\n",
    "  --use_8bit_adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model you just made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import diffusers\n",
    "import transformers\n",
    "from diffusers import StableDiffusionDepth2ImgPipeline\n",
    "import os\n",
    "from jupyter_compare_view import compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Getting model from {os.environ.get(\"OUTPUT_DIR\")}')\n",
    "pipeline = StableDiffusionDepth2ImgPipeline.from_pretrained(os.environ.get('OUTPUT_DIR'))\n",
    "pipeline = pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an image as an input depth map\n",
    "image_path = \"/workspace/content/data/samples/village.jpg\" # replace with whatever you want\n",
    "image = PIL.Image.open(image_path)\n",
    "\n",
    "image_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "image = image_transform(image)\n",
    "image = image[None,:,:,:]\n",
    "image = image.to(\"cuda\")\n",
    "depth_map = pipeline.depth_estimator(image).predicted_depth\n",
    "image = transforms.ToPILImage()(image[0])\n",
    "depth_min = torch.amin(depth_map, dim=[0, 1, 2], keepdim=True)\n",
    "depth_max = torch.amax(depth_map, dim=[0, 1, 2], keepdim=True)\n",
    "depth_map = 2.0 * (depth_map - depth_min) / (depth_max - depth_min) - 1.0\n",
    "depth_map = depth_map[0,:,:]\n",
    "depth_map = transforms.ToPILImage()(depth_map)\n",
    "compare(depth_map, image, cmap=\"gray\", start_mode=\"horizontal\", start_slider_pos=0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline(\"a photo of <your instance>, standing, Kodachrome, Canon 5D, f2 aperture, extremely detailed, sharp focus\", image)\n",
    "compare(result[0][0], image, cmap=\"gray\", start_mode=\"horizontal\", start_slider_pos=0.73)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afaf7b9974a9993a24921efe4bafd795ec4a11fdf3793e227c3c50c68c1d8d32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
